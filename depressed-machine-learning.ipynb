{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd3d5ac",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-22T07:53:21.173147Z",
     "iopub.status.busy": "2024-11-22T07:53:21.172769Z",
     "iopub.status.idle": "2024-11-22T07:53:22.113398Z",
     "shell.execute_reply": "2024-11-22T07:53:22.112270Z"
    },
    "papermill": {
     "duration": 0.948304,
     "end_time": "2024-11-22T07:53:22.116319",
     "exception": false,
     "start_time": "2024-11-22T07:53:21.168015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s4e11/sample_submission.csv\n",
      "/kaggle/input/playground-series-s4e11/train.csv\n",
      "/kaggle/input/playground-series-s4e11/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad7c2d",
   "metadata": {
    "papermill": {
     "duration": 0.002312,
     "end_time": "2024-11-22T07:53:22.121766",
     "exception": false,
     "start_time": "2024-11-22T07:53:22.119454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1) Data Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433dc348",
   "metadata": {
    "papermill": {
     "duration": 0.002302,
     "end_time": "2024-11-22T07:53:22.126426",
     "exception": false,
     "start_time": "2024-11-22T07:53:22.124124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## configuring training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5614fbc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:53:22.133836Z",
     "iopub.status.busy": "2024-11-22T07:53:22.132445Z",
     "iopub.status.idle": "2024-11-22T07:53:22.797715Z",
     "shell.execute_reply": "2024-11-22T07:53:22.796494Z"
    },
    "papermill": {
     "duration": 0.671128,
     "end_time": "2024-11-22T07:53:22.799952",
     "exception": false,
     "start_time": "2024-11-22T07:53:22.128824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.77\n",
      "fillNaN complete\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/playground-series-s4e11/train.csv\")\n",
    "# first imma get rid of the columns that obviously have no relation to whether one has depression or not\n",
    "# removing columns 'id' and 'Name'\n",
    "train_data.drop(['id', 'Name'], axis=1, inplace=True)\n",
    "\n",
    "# function to check for NaN values in a column\n",
    "def checknan(colname):\n",
    "    print(train_data[train_data[colname].isna()])\n",
    "\n",
    "# function to fillna with either mean, median, 0, or another column\n",
    "def fillNaN(colnamelist, type, othercol=None):\n",
    "    if type == 'mean':\n",
    "        for colname in colnamelist:\n",
    "            train_data.fillna({colname: train_data[colname].mean()}, inplace = True)\n",
    "    elif type == 'median':\n",
    "        for colname in colnamelist:\n",
    "            train_data.fillna({colname: train_data[colname].median()}, inplace = True)\n",
    "    elif type == 0:\n",
    "        for colname in colnamelist:\n",
    "            train_data.fillna({colname: 0}, inplace = True)\n",
    "    elif type == 'othercol':\n",
    "        for colname in colnamelist:\n",
    "            train_data.fillna({colname: train_data[othercol]}, inplace = True)\n",
    "    print('fillNaN complete')\n",
    "        \n",
    "# dealing with NaNs in column: Profession\n",
    "train_data['Profession'] = train_data['Profession'].fillna(train_data['Working Professional or Student'])\n",
    "\n",
    "# dealing with NaNs in columns: Academic Pressure & Work Pressure\n",
    "train_data['Work Pressure'] = train_data['Work Pressure'].fillna(train_data['Academic Pressure'])\n",
    "train_data['Pressure'] = train_data['Work Pressure']\n",
    "train_data.drop(['Work Pressure', 'Academic Pressure'], axis=1, inplace=True)\n",
    "train_data.fillna({'Pressure': 0}, inplace=True)\n",
    "\n",
    "# dealing with NaNs in column: CGPA\n",
    "print(train_data['CGPA'].median())\n",
    "train_data['CGPA'] = train_data['CGPA'].fillna(train_data['CGPA'].median())\n",
    "\n",
    "# dealing with NaNs in columns: Study Satisfaction and Job Satisfaction\n",
    "train_data['Job Satisfaction'] = train_data['Job Satisfaction'].fillna(train_data['Study Satisfaction'])\n",
    "train_data.fillna({'Job Satisfaction': train_data['Job Satisfaction'].mean()}, inplace=True)\n",
    "train_data['Career Satisfaction'] = train_data['Job Satisfaction']\n",
    "train_data.drop(['Job Satisfaction', 'Study Satisfaction'], axis=1, inplace=True)\n",
    "\n",
    "# Dietary Habits and Degree columns\n",
    "train_data.fillna({'Degree': 'Unknown Degree', 'Dietary Habits': 'Moderate'}, inplace=True)\n",
    "\n",
    "# Financial Stress\n",
    "fillNaN(['Financial Stress'], 'mean')\n",
    "\n",
    "traincities = train_data['City'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb945af",
   "metadata": {
    "papermill": {
     "duration": 0.002319,
     "end_time": "2024-11-22T07:53:22.805015",
     "exception": false,
     "start_time": "2024-11-22T07:53:22.802696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## configuring test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6072e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:53:22.812125Z",
     "iopub.status.busy": "2024-11-22T07:53:22.811068Z",
     "iopub.status.idle": "2024-11-22T07:53:23.208869Z",
     "shell.execute_reply": "2024-11-22T07:53:23.207726Z"
    },
    "papermill": {
     "duration": 0.403908,
     "end_time": "2024-11-22T07:53:23.211396",
     "exception": false,
     "start_time": "2024-11-22T07:53:22.807488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8\n",
      "fillNaN complete\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"/kaggle/input/playground-series-s4e11/test.csv\")\n",
    "# can only get rid of the 'Name' column as the id column is needed for submission\n",
    "test_data.drop(['Name'], axis=1, inplace=True)\n",
    "\n",
    "# function to check for NaN values in a column\n",
    "def checknan(colname):\n",
    "    print(test_data[test_data[colname].isna()])\n",
    "\n",
    "# function to fillna with either mean, median, 0, or another column\n",
    "def fillNaN(colnamelist, type, othercol=None):\n",
    "    if type == 'mean':\n",
    "        for colname in colnamelist:\n",
    "            test_data.fillna({colname: train_data[colname].mean()}, inplace = True) # fillna with training data mean\n",
    "    elif type == 'median':\n",
    "        for colname in colnamelist:\n",
    "            test_data.fillna({colname: train_data[colname].median()}, inplace = True) # fillna with training data median\n",
    "    elif type == 0:\n",
    "        for colname in colnamelist:\n",
    "            test_data.fillna({colname: 0}, inplace = True)\n",
    "    elif type == 'othercol':\n",
    "        for colname in colnamelist:\n",
    "            test_data.fillna({colname: test_data[othercol]}, inplace = True)\n",
    "    print('fillNaN complete')\n",
    "        \n",
    "# dealing with NaNs in column: Profession\n",
    "test_data['Profession'] = test_data['Profession'].fillna(test_data['Working Professional or Student'])\n",
    "\n",
    "# dealing with NaNs in columns: Academic Pressure & Work Pressure\n",
    "test_data['Work Pressure'] = test_data['Work Pressure'].fillna(test_data['Academic Pressure'])\n",
    "test_data['Pressure'] = test_data['Work Pressure']\n",
    "test_data.drop(['Work Pressure', 'Academic Pressure'], axis=1, inplace=True)\n",
    "test_data.fillna({'Pressure': 0}, inplace=True)\n",
    "\n",
    "# dealing with NaNs in column: CGPA\n",
    "print(test_data['CGPA'].median())\n",
    "test_data['CGPA'] = test_data['CGPA'].fillna(train_data['CGPA'].median())\n",
    "\n",
    "# dealing with NaNs in columns: Study Satisfaction and Job Satisfaction\n",
    "test_data['Job Satisfaction'] = test_data['Job Satisfaction'].fillna(test_data['Study Satisfaction'])\n",
    "test_data.fillna({'Job Satisfaction': train_data['Career Satisfaction'].mean()}, inplace=True)\n",
    "test_data['Career Satisfaction'] = test_data['Job Satisfaction']\n",
    "test_data.drop(['Job Satisfaction', 'Study Satisfaction'], axis=1, inplace=True)\n",
    "\n",
    "# Dietary Habits and Degree columns\n",
    "test_data.fillna({'Degree': 'Unknown Degree', 'Dietary Habits': 'Moderate'}, inplace=True)\n",
    "\n",
    "# Financial Stress\n",
    "fillNaN(['Financial Stress'], 'mean')\n",
    "testcities = test_data['City'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571032f1",
   "metadata": {
    "papermill": {
     "duration": 0.002372,
     "end_time": "2024-11-22T07:53:23.216556",
     "exception": false,
     "start_time": "2024-11-22T07:53:23.214184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## manually getting dummy columns for the unique city names -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1aedcb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:53:23.223708Z",
     "iopub.status.busy": "2024-11-22T07:53:23.222738Z",
     "iopub.status.idle": "2024-11-22T07:53:41.197156Z",
     "shell.execute_reply": "2024-11-22T07:53:41.196127Z"
    },
    "papermill": {
     "duration": 17.98056,
     "end_time": "2024-11-22T07:53:41.199540",
     "exception": false,
     "start_time": "2024-11-22T07:53:23.218980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Leela', 'Ira', 'Is Kanpur', 'Vaikot', 'Thani', 'Avni', 'Saurav', 'Vaishnavi', 'Patna', 'Ghopal', 'Nalini', 'No', 'Jaipur', 'More Delhi', 'Kanpur', 'Golkata', 'Chennai', 'Parth', 'City', 'Mhopal', 'Less Delhi', 'Vadodara', 'Meerut', 'Indore', 'Kalyan', 'Varanasi', 'Vasai-Virar', 'Bhopal', 'Ghaziabad', 'Ludhiana', 'Less than 5 hours', 'Malyan', 'Bhavna', 'Delhi', 'Rajkot', 'Keshav', 'Pratyush', 'Chemist', 'San Vasai-Virar', 'Saanvi', 'Hrithik', 'Ahmedabad', 'Unaly', 'Surat', 'Agra', 'Vikram', 'Pune', 'Srinagar', 'Aditi', 'Bangalore', 'Lucknow', 'Vidhi', 'Rolkata', 'Siddhesh', 'Thane', 'Nashik', 'Faridabad', 'Sara', 'Nagpur', 'Mumbai', 'Vidya', 'Visakhapatnam', 'Pratham', 'Lawyer', 'Abhinav', 'Kolkata', 'Hyderabad', 'No.12'}\n",
      "68\n",
      "{'Aditya', 'Chhavi', 'Anvi', 'MCA', 'Chennai', 'Vadodara', 'Bhopal', 'Ghaziabad', 'Less than 5 Kalyan', 'Mira', 'Kashish', 'Galesabad', 'Krishna', 'Krinda', 'Jhanvi', 'Kolkata', 'Khushi', 'Pooja', 'Patna', '3.0', 'M.Tech', 'Harsha', 'Ishkarsh', 'City', 'Less Delhi', 'Ivaan', 'Meerut', 'Indore', 'Bhavna', 'Varanasi', 'Vasai-Virar', 'Tolkata', 'Rajkot', 'Aishwarya', 'Saanvi', 'Gurgaon', 'Gaurav', 'M.Com', 'Ahmedabad', 'Ayansh', 'Surat', 'Malyansh', 'Khaziabad', 'Pune', 'Faridabad', 'Morena', 'Armaan', 'Kagan', 'Ishanabad', 'Vaanya', 'Kibara', 'Raghavendra', 'Reyansh', 'Vaishnavi', 'Researcher', 'No', 'Aaradhya', 'Parth', 'Rashi', 'Kalyan', 'Ludhiana', 'Atharv', 'Keshav', 'Dhruv', 'Pratyush', 'Srinagar', 'Bangalore', 'Moreadhyay', 'Thane', 'Unirar', 'Mihir', 'Vidya', 'ME', 'Itheg', 'MSc', 'Harsh', 'Nalini', 'Jaipur', 'Kanpur', 'Molkata', 'Nalyan', 'Delhi', 'Mahi', 'Agra', 'Ayush', 'Lucknow', 'Shrey', 'Nandini', 'Vidhi', 'Nashik', 'Kashk', 'Nagpur', 'Ithal', 'Mumbai', 'Visakhapatnam', 'Tushar', 'Hyderabad', 'Plata'}\n",
      "98\n",
      "['Leela', 'Thani', 'Aditya', 'Chhavi', 'Anvi', 'MCA', 'Chennai', 'Vadodara', 'Bhopal', 'Ghaziabad', 'Less than 5 Kalyan', 'San Vasai-Virar', 'Mira', 'Aditi', 'Kashish', 'Galesabad', 'Krishna', 'Krinda', 'Jhanvi', 'Pratham', 'Abhinav', 'Kolkata', 'Khushi', 'Pooja', 'Patna', '3.0', 'M.Tech', 'Harsha', 'Ishkarsh', 'City', 'Less Delhi', 'Ivaan', 'Meerut', 'Indore', 'Less than 5 hours', 'Varanasi', 'Vasai-Virar', 'Bhavna', 'Tolkata', 'Chemist', 'Rajkot', 'Aishwarya', 'Saanvi', 'Gurgaon', 'Gaurav', 'M.Com', 'Hrithik', 'Ahmedabad', 'Ayansh', 'Surat', 'Malyansh', 'Khaziabad', 'Pune', 'Siddhesh', 'Faridabad', 'Morena', 'Armaan', 'Kagan', 'Ishanabad', 'Lawyer', 'Is Kanpur', 'Vaanya', 'Kibara', 'Raghavendra', 'Reyansh', 'Vaishnavi', 'Researcher', 'Ghopal', 'No', 'More Delhi', 'Aaradhya', 'Parth', 'Rashi', 'Kalyan', 'Ludhiana', 'Atharv', 'Keshav', 'Dhruv', 'Pratyush', 'Unaly', 'Srinagar', 'Bangalore', 'Moreadhyay', 'Thane', 'Unirar', 'Vidya', 'Mihir', 'ME', 'Vikram', 'No.12', 'Ira', 'Vaikot', 'Avni', 'Saurav', 'Itheg', 'MSc', 'Harsh', 'Nalini', 'Jaipur', 'Kanpur', 'Golkata', 'Molkata', 'Nalyan', 'Mhopal', 'Malyan', 'Delhi', 'Mahi', 'Agra', 'Ayush', 'Lucknow', 'Shrey', 'Nandini', 'Vidhi', 'Rolkata', 'Nashik', 'Sara', 'Kashk', 'Nagpur', 'Ithal', 'Mumbai', 'Visakhapatnam', 'Tushar', 'Hyderabad', 'Plata']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/2583383832.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.at[index, cityname] = True\n",
      "/tmp/ipykernel_17/2583383832.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.at[index, cityname] = True\n",
      "/tmp/ipykernel_17/2583383832.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.at[index, cityname] = True\n",
      "/tmp/ipykernel_17/2583383832.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.at[index, cityname] = True\n",
      "/tmp/ipykernel_17/2583383832.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.at[index, cityname] = True\n",
      "/tmp/ipykernel_17/2583383832.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.at[index, cityname] = True\n",
      "/tmp/ipykernel_17/2583383832.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.at[index, cityname] = True\n"
     ]
    }
   ],
   "source": [
    "# checking if the cities in the train data and test data are the same\n",
    "print(set(testcities))\n",
    "print(len(testcities)) #68 cities in the testing data\n",
    "\n",
    "print(set(traincities))\n",
    "print(len(traincities)) #98 cities in the training data\n",
    "\n",
    "# creating a list of all cities \n",
    "allcities = list(set(testcities) | set(traincities)) # length of all cities = 124\n",
    "print(allcities)\n",
    "# manually getting dummy city columns for both training and test datasets\n",
    "for name in allcities:\n",
    "    for df in [train_data, test_data]:\n",
    "        df['name'] = False\n",
    "\n",
    "# manually inputting the city for each row\n",
    "# (if the person in that row resides in said city, value of the city column becomes from False to True)\n",
    "for df in [train_data, test_data]:\n",
    "    for index, row in df.iterrows():\n",
    "        cityname = row['City']\n",
    "        df.at[index, cityname] = True\n",
    "# removing the city column, its not needed anymore yay\n",
    "for df in [train_data, test_data]:\n",
    "    df.drop('City', axis=1 , inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10008389,
     "sourceId": 84895,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.162317,
   "end_time": "2024-11-22T07:53:41.723237",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-22T07:53:18.560920",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
